
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jawakar-7/Image-Classification-using-multiple-models-/blob/main/Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NR-CMGRC9mF1"
      },
      "source": [
        "### Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Jawakar-7/Image-Classification-using-multiple-models-.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTRrm9RF-oaX",
        "outputId": "ba8f42ce-5e11-449e-d362-edf90458b017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Image-Classification-using-multiple-models-'...\n",
            "remote: Enumerating objects: 24319, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 24319 (delta 0), reused 0 (delta 0), pack-reused 24316\u001b[K\n",
            "Receiving objects: 100% (24319/24319), 342.22 MiB | 38.73 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "Updating files: 100% (24340/24340), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKHFtEFc9mF4"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from  keras.models import Sequential\n",
        "from keras.layers import Activation , BatchNormalization , Dense , Dropout , Flatten , MaxPooling2D,Conv2D\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from  keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path='/content/Image-Classification-using-multiple-models-/Datasets/seg_test/seg_test'\n",
        "test_path='/content/Image-Classification-using-multiple-models-/Datasets/seg_train/seg_train'"
      ],
      "metadata": {
        "id": "O04bPjY_eDlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijT0peLB9mF6"
      },
      "source": [
        "##Dataset Preparation\n",
        "Here the images are in seg_test,seg_train folders we will be accesing every image and Scale ,resizing it .\n",
        "We will be using keras.preprocessing module to access data from the directory and classify it.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_gen_train=ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    rotation_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    width_shift_range=0.2,\n",
        "    fill_mode='nearest'\n",
        ")"
      ],
      "metadata": {
        "id": "kn0Is2eKcWOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_size=(150,150)\n",
        "batch_size=32"
      ],
      "metadata": {
        "id": "poN1NSLjy04p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_gen_test=ImageDataGenerator(\n",
        "    rescale=1.0/255\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "D7K9yEOwdLn2",
        "outputId": "966ea96b-d3e2-4def-ef95-8a72f7724d7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2510a42cf0ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m data_gen_test=ImageDataGenerator(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mrescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train=data_gen_train.flow_from_directory(train_path,\n",
        "                                           target_size=img_size,\n",
        "                                                color_mode='rgb',\n",
        "                                                class_mode='categorical',\n",
        "                                                batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eo12LypEy_Mk",
        "outputId": "7aa806a0-4540-406e-d660-e0e6527ed64e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3000 images belonging to 6 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/94 [00:51<?, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSlK45wJ9mF6",
        "outputId": "2712b3db-1c0a-4221-f69b-c7bb0486b29e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'mountain': 0, 'street': 1, 'glacier': 2, 'buildings': 3, 'sea': 4, 'forest': 5}\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8n0vcIhO9mF7"
      },
      "source": [
        " here we are writing a whole new function to access the images and return as (X_train,Y_train),(X_test,Y-test) tuple output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBR8ASxT9mF7"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.utils import load_img\n",
        "# import os\n",
        "# from tqdm import tqdm\n",
        "# Img_size=(150,150)\n",
        "# def get_data():\n",
        "#     data_paths=[\"/content/Image-Classification-using-multiple-models-/Datasets/seg_train/seg_train\",\"/content/Image-Classification-using-multiple-models-/Datasets/seg_test/seg_test\"]\n",
        "#     output=[]#we will be saving the images and labels tuples here and returning\n",
        "#     for data in data_paths:\n",
        "#         #inside the train/test folders\n",
        "#         images=[]\n",
        "#         labels=[]\n",
        "#         print(\"loading {}\".format(data_paths))\n",
        "#         for places in os.listdir(data):\n",
        "#             #accesing subfolders like buildings,forest etc\n",
        "#             label_name=class_label_names[places]\n",
        "\n",
        "#             for image in tqdm(os.listdir(os.path.join(data,places))):\n",
        "#                 img_path=os.path.join(os.path.join(data,places),image)\n",
        "\n",
        "#                 image=load_img(img_path,Img_size,color_mode='rgb')\n",
        "#                 # we can also use the below code to preprocess the image\n",
        "#                 # image = cv2.imread(img_path)\n",
        "#                 # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "#                 # image = cv2.resize(image, IMAGE_SIZE)\n",
        "#                 images.append(image)\n",
        "#                 labels.append(label_name)\n",
        "#                 #print(len(images),len(labels))\n",
        "#                 #images are added after alteration respective to their labels to the images and labels lists\n",
        "#                 #print(\"completed for {}\".format(places))\n",
        "#         #after completion of first set(training set ) the images are converted to arrays for easier computation\n",
        "#         # this can be done by using the img_to_array function from keras.utils also\n",
        "#         images = np.array(images)\n",
        "#         labels = np.array(labels, dtype = 'int32')\n",
        "#         output.append((images,labels))\n",
        "#     return(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hM5f8S9O9mF8",
        "outputId": "22b5ae4f-0b1d-4fb6-ddbe-f41e635ac4d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading ['/content/Image-Classification-using-multiple-models-/Datasets/seg_train/seg_train', '/content/Image-Classification-using-multiple-models-/Datasets/seg_test/seg_test']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/2382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/keras/utils/image_utils.py:409: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
            "  warnings.warn(\n",
            "100%|██████████| 2382/2382 [00:01<00:00, 1649.48it/s]\n",
            "100%|██████████| 2274/2274 [00:01<00:00, 1794.05it/s]\n",
            "100%|██████████| 2512/2512 [00:01<00:00, 1822.07it/s]\n",
            "100%|██████████| 2191/2191 [00:01<00:00, 1196.39it/s]\n",
            "100%|██████████| 2271/2271 [00:01<00:00, 1172.98it/s]\n",
            "100%|██████████| 2404/2404 [00:01<00:00, 1431.29it/s]\n",
            "<ipython-input-4-5ec4b966532e>:32: FutureWarning: The input object of type 'Image' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Image', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  images = np.array(images)\n",
            "<ipython-input-4-5ec4b966532e>:32: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  images = np.array(images)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading ['/content/Image-Classification-using-multiple-models-/Datasets/seg_train/seg_train', '/content/Image-Classification-using-multiple-models-/Datasets/seg_test/seg_test']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 501/501 [00:00<00:00, 1824.44it/s]\n",
            "100%|██████████| 510/510 [00:00<00:00, 1871.32it/s]\n",
            "100%|██████████| 525/525 [00:00<00:00, 1966.75it/s]\n",
            "100%|██████████| 437/437 [00:00<00:00, 1884.41it/s]\n",
            "100%|██████████| 474/474 [00:00<00:00, 1640.68it/s]\n",
            "100%|██████████| 553/553 [00:00<00:00, 1738.46it/s]\n"
          ]
        }
      ],
      "source": [
        "# (train_images, train_labels), (test_images, test_labels) = get_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "aSWlbh1aBQbo",
        "outputId": "5c648e24-8ffa-44c4-feb4-71b405ef19a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-4cc397dfcdf1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# test_images=np.array(test_images,dtype='float32')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'Image'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PXprGAqOBjC1"
      },
      "execution_count": null,
      "outputs": []
    }
